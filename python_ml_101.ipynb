{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python for Machine Learning\n",
    "\n",
    "## Maciej Szankin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Howdy folks and thank you for joining!\n",
    "This presentation \"Python for Machine Learning\" will be an introduction, to python for machine learning, but also to some of the tools that will be used in other sessions led by other speakers as well, so I hope you will find it helpful and that it will aid you make the most out of the School.\n",
    "\n",
    "As this is the first session that even preceeds introduction to the Machine Learning, we will be mostly focusing on what and how to use to achieve results, rather than dive deep into the math behind it.\n",
    "\n",
    "In this session I make an assumption that you have at least very basic understanding what Python is and that you have used it at least once, but nevertheless I will try to cover some of the basics principles of Python programming as well. I will not cover all of them, as this session is far too short to allow for it, but instead I've hand picked some of the topics that I think are particulary usefull when applying Python to Machine Learning oriented tasks.\n",
    "\n",
    "As it is middle of the night here, actually it's 3am, if at any point you think that I am diverging from topic, please let me know in chat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About me\n",
    "\n",
    "<div style=\"float:left; padding:30px;\">\n",
    "    <img src=\"https://d2svrcwl6l7hz1.cloudfront.net/content/B007JLD2QC/resources/0?mime=image/*\" style=\"width:300px;\" />\n",
    "    <center><i>Source: <a href=\"https://www.amazon.com/Am-Pole-So-Can-You/dp/1619695022\" target=\"_blank\">amazon.com</a></i></center>\n",
    "</div>\n",
    "<div style=\"float:left; padding:30px;\">\n",
    "    <h2>Maciej Szankin</h2>\n",
    "    <h4>Deep Learning Software Engineer @ Intel</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "As you may have noticed on the previous slide, I am Maciej Szankin, I am a Pole living and working in the United States.\n",
    "\n",
    "It's a Pole with a capital P - __SPACE__ That's more like it!\n",
    "\n",
    "I am a deep learning software engineer working for Intel in San Diego, California.\n",
    "My work focuses on Deep Learning for computer vision, more recently it's more into NLP, and related optimizations for a CPU and more resource constrained devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About me\n",
    "\n",
    "<div style=\"float:left; padding:30px;\">\n",
    "    <img src=\"https://avatars0.githubusercontent.com/u/4785345?s=460&u=347ee5cbd03d6f3972af3b66ec530eef19f1af1e&v=4\" style=\"width:300px;\" />\n",
    "</div>\n",
    "<div style=\"float:left; padding:30px;\">\n",
    "    <h2>Maciej Szankin</h2>\n",
    "    <h4>Deep Learning Software Engineer @ Intel</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "As you may have noticed on the previous slide, I am Maciej Szankin, I am a Pole living and working in the United States.\n",
    "\n",
    "It's a Pole with a capital P - __SPACE__ That's more like it!\n",
    "\n",
    "I am a deep learning software engineer working for Intel in San Diego, California.\n",
    "My work focuses on Deep Learning for computer vision, more recently it's more into NLP, and related optimizations for a CPU and more resource constrained devices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction - How do I participate?\n",
    "\n",
    "* Slack #ml\n",
    "* Run Locally\n",
    "    1. Install Python\n",
    "        * Python\n",
    "        * Anaconda\n",
    "    2. Run...\n",
    "        * ... as a script\n",
    "        * ... in a REPL\n",
    "        * ... in a Notebook\n",
    "    \n",
    "* Run Remotely\n",
    "    * Google Colab\n",
    "    * ML Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So, before we even begin talking about programming and Machine Learning, let's start with what is needed to get the most out of this and following sessions.\n",
    "\n",
    "First of all, if you haven't yet created an account on our Slack, please do, as all organizational stuff will be announced in the #general channel, and also it's a great way for all of us to communicate, post questions and answers. As this presentation is realted to ML if you have any questions to me or questions related to the topic that someone else can answer, please post them there. During this presentation you can also use zoom's chat to ask a question or let me know that I am going too fast or too slow.\n",
    "\n",
    "All other sessions also have slack channels setup. If you ever feel lost which channel to use, please go to the schedukle availabvle on our website __GO TO THE WEBSITE AND SHOW__\n",
    "\n",
    "Next thing is getting the environment setup.\n",
    "There are few options for you to consider.\n",
    "1. One - you can use your own machine and install all packages there\n",
    "2. or two - you can use one of the remote services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction | Run Locally\n",
    "\n",
    "* If you are on Linux or Mac you should have Python availabile\n",
    "* For Windows users: https://www.python.org/downloads/windows/\n",
    "\n",
    "__... but either way you should really use Anaconda__\n",
    "\n",
    "* It's a Python distribution - manage not only Python packages, but also additional libraries / drivers\n",
    "* Get it from: https://www.anaconda.com/products/individual\n",
    "* `conda install` vs `pip install`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So - the first option. Running locally. For this you will need a python interpreter installed in your system, which I hope everyone has.\n",
    "If you are a Linux or Mac user, there is a high chance that you already have it installed, for Windows, as far as I am aware, you have to download the installer and do it.\n",
    "In any of these cases, but please, don't stop here, as usually default installations are not the best for you. They are the best for a generic/common case, but you are not a common case, right?\n",
    "\n",
    "There is this thing called Anaconda. You might have also heard it being refered to as just \"conda\". What anaconda is, it's a python distribution. Think like Anaconda->Ubuntu, Python-> Linux. It's really great as it does solve a lot of issues which you may enounter, especially in the data science field. THe main selling point is that it not only allows for managing python packages, but also additional libraries and drivers. So you no longer have to go to the hardware manufacturers website, download drivers or a library, go through installation only to discover that the python package you want to use requires older driver version. I've been there so many times and I did break a lot of systems while resolving dependency hells, so discovering anaconda for me felt like a breeze after a firestorm.\n",
    "\n",
    "When you use anaconda, as it's a beefier management tool for python, you still have access to python tool that everyone know and love - the PIP, the Pip Installs Packages.\n",
    "\n",
    "Actually I just recently discovered what PIP stands for. I have always thought it is Package Installer for Python. Turns out I was wrong for many years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction | Anaconda + Intel Distribution for Python\n",
    "\n",
    "* CPU-focused optimizations are included\n",
    "* MKL support in most packages by default\n",
    "\n",
    "\n",
    "* Intel¬Æ Distribution for Python* and Intel¬Æ Performance Libraries with Anaconda\n",
    "    * https://software.intel.com/content/www/us/en/develop/articles/using-intel-distribution-for-python-with-anaconda.html\n",
    "    * https://software.intel.com/content/www/us/en/develop/articles/intel-optimization-for-tensorflow-installation-guide.html\n",
    "* Read more: https://www.anaconda.com/blog/tensorflow-cpu-optimizations-in-anaconda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Another great thing about anaconda is that it's a great Bang for the buck. Not only because it's free, but also because many of the existing python libraries have been rebuilt for conda and so they will outperform pip installations. when you install using pip you get a pythin package that matches your CPU architecture and the operating system, but that's it. And with CPU there is more to consider than simply 32- or 64-bit architecture. Packages available through conda have been built against additional libraries and extra flags, thanks to which you are not getting a generic package that runs on 99% of the machines on the internet, but rather a package that targets a group of machines similar to the one you are using. It's like having a package built from source, but without having to meet all the dependencies manually and going through the iterative process of discovering which build configuration works the best for you.\n",
    "\n",
    "If you have Intel CPUs most of the packages, like NumPy, TensorFlow or PyTorch installed through conda will include this kind of optimizations thanks to Intel's MKL (math kernel library). No additional steps are needed!\n",
    "\n",
    "However, if you want to have the latest and greatest improvements available through conda you can go and look for Intel Distribution for Python. It's a more targeted package channel than the conda's main channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Run as a script\n",
    "* or use Jupyter Notebook\n",
    "\n",
    "```bash\n",
    "pip install jupyter\n",
    "\n",
    "# or even better:\n",
    "conda install jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "OK. Now that you all should have Python installed, either from your system or conda, functionality wise it doesn;t matter. You will be able to follow using either of these.\n",
    "\n",
    "you can either just write a script in your favorite editor and run in in a command line or, if you prefer, you can use jupyter notebooks. If you have never heard of a jupyter notebook, basically what it is is a browser based environment which allows for executing python (but not only) code snippets, while remembering the state of each of the snippets so you do not have to re-run them again - at least not within the same session. Jupyter Notebooks are one of the most popular tools in data science and they allow for expresiveness in your code, as you can mix scripts with markdown documentation and you can even plot charts in between.\n",
    "\n",
    "You can get jupyter notebook installed by running either if these commands.\n",
    "\n",
    "We will go through next slides on alternative ways of running notebooks and then we will talk about them in a little bit more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction | Notebooks\n",
    "\n",
    "```bash\n",
    "cd ~/workspace/\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So, if you are using local installation, you just have to run jupyter notebook command in the directory which you think is worthy of being your workspace directory, and that's it. A new browser tab should open.\n",
    "\n",
    "If this is your choice just hang on there, we will get back to the notebook in a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction | Run Remotely\n",
    "\n",
    "* Google Colab\n",
    "* ML Server -  http://ml.eti.pg.gda.pl/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In the meantime.\n",
    "\n",
    "You don't really have to install anything locally. You can use one of the remote services which allows for hosting and running your code on someone's else computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction | Run Remotely | Google Colab\n",
    "\n",
    "* Available at https://colab.research.google.com/\n",
    "* It's free! You only need a Google account to access\n",
    "* Offers different environment: CPU / GPU / TPU\n",
    "* Resources are not guaranteed\n",
    "* Avoid hogging resources - you can get lower priority in the future if requested resources are not actievely used!\n",
    "* For improved experience - Colab Pro - https://colab.research.google.com/signup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "First of the remote ways is to use Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* You can execute bash commands in a cell.\n",
    "* Prepend your command with ! to run it in a shell\n",
    "* When running Google Colab you get your own virtualized environment - you can install packages\n",
    "* The environment will be cleaned upon exiting - make your life easier and install all additional dependencies in the first cell.\n",
    "\n",
    "* Example command to install Python's wget:\n",
    "\n",
    "    ```bash\n",
    "    !pip install wget\n",
    "    ```\n",
    "    Verify:\n",
    "\n",
    "    ```python\n",
    "    import wget\n",
    "    wget.__version__\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__PUNKTY__\n",
    "\n",
    "we will get back to the commands later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction | Run Remotely | ML Server\n",
    "\n",
    "* Available at http://ml.eti.pg.gda.pl/\n",
    "* JupyterHub-based preconfigured environment deployed for this School\n",
    "* Server is located in Gdansk, Poland\n",
    "* Use it if you can't use Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "if for any reason you don't or can't use google colab, we also have our in-house deployment for jupyter notebooks based on a JupyterHub. It works in a very similar way and the experience is nearly identical. However, as the ML server is not as distributed and scalable as Google Colab, if you can - stick with Colab. If not - please reach out to me on Slack, you can send me a PM, once again my name is Maciej Szankin and if it's hard to remember you can go to the #general channel on slack and you will find me, as i've been posting annoucenements before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* You can execute bash commands in a cell.\n",
    "* Installing new packages: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "on the ML server you can also execute bash commands in a cell, BUT\n",
    "\n",
    "you cant install new packages. We just dont have the scale to give such wide permissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><h2>You can't! Sorry! üíî</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction | Notebook Tricks\n",
    "\n",
    "* Command dialog - `cmd + shift + p` / `ctrl + shift + p`\n",
    "    * `Esc` command mode\n",
    "    * `m` / `y` to switch cell's type to markdown/code\n",
    "    * `a` / `b` to insert a new cell above/below the current cell\n",
    "    * `shift + tab` to show doc for the selected object\n",
    "    * `ctrl + shift + -` to split cell in half at cursor's position\n",
    "* Bash commands in a cell - `!<bash_command>`\n",
    "* Cell with different kernel (`%%bash`/`%%HTML`/`%%python2`/`%%python3`/`%%ruby`/`%%perl`)\n",
    "* Python variables in bash\n",
    "* LaTeX - `$ formula $`\n",
    "* Magic commands\n",
    "    * `%<CMD> <Python line of code>`\n",
    "    * `%%<CMD>\n",
    "      <Python block of code>`\n",
    "    * `%time / %%time`\n",
    "    * `%timeit / %%timeit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "...\n",
    "* Command dialog - `cmd + shift + p` / `ctrl + shift + p`\n",
    "  `Note that if you have a pocket extension installed in your browser,on MacOS the cmd shift p shortcut has a conflict with this extension, so you have to disable it, or if you keep on pressing this shortcut you will end up with few additions of your notebook to your pocket account.`\n",
    "  \n",
    "* Bash commands in a cell - !<bash_command>\n",
    "  ```\n",
    "  !pip list\n",
    "  ```\n",
    "* Cell with different kernel\n",
    "  ```\n",
    "  %%bash\n",
    "  for i in {1..5}\n",
    "  do echo $i;\n",
    "  done;\n",
    "  ```\n",
    "* Python variables in bash\n",
    "  ```\n",
    "  foo = 'bar'\n",
    "  !echo $foo\n",
    "  ```\n",
    "* LaTeX\n",
    "  ```\n",
    "  $P(A \\mid B) = \\frac{P(B \\mid A)P(A)}{P(B)}$\n",
    "  ```\n",
    "* Magic commands\n",
    "    * `%<CMD> <Python line of code>`\n",
    "    * `%%<CMD>\n",
    "      sum(range(10000000))`\n",
    "    * `%time / %%time`\n",
    "    * `%timeit / %%timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Markdown__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üêç Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://imgs.xkcd.com/comics/python.png\" alt=\"Python: https://xkcd.com/353/\" />\n",
    "    <div><i>Source: <a href=\"https://xkcd.com/353/\" target=\"_blank\">XKCD 353</a></i></div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So, we got to python. Python is an amazingly flexible scripting language and it can be used for so many things. You will find it being used in the clouds, in your computers, in the embedded devices, it's used as a website's backend, API. It's really a tool that can be applied to solve a vast number of tasks, mostly because of the amazing community which supplies a package for nearly anything that you can think of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Object Oriented\n",
    "* however #1 - no explicit encapsulation: \"After all, we're all consenting adults here.\"\n",
    "* however #2 - no class interface, only (multi)inheritance\n",
    "* multi-paradigm\n",
    "* interpreted\n",
    "* strongly typed\n",
    "* dynamically typed\n",
    "* ü¶Ü duck typing\n",
    "* garbage collector\n",
    "* designed for code clarity\n",
    "* object introspection\n",
    "* interactive mode (terminal / IPython)\n",
    "* interfaces to many popular programming languages:\n",
    "    * C++\n",
    "    * Java\n",
    "    * .NET\n",
    "    * and many others\n",
    "* has it's own package manager - pip & easy_install\n",
    "* before writing a library - check if it exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Now, just as I said before, We will do a general overview of the Python, some programming experience is expected.\n",
    "* Before we go into python code let's quickly go through some features that make python great, especially for data science\n",
    "\n",
    "* Object Oriented\n",
    "     * Python does support object oriented programming. Object-oriented programming is a programming paradigm that provides a means of structuring programs so that properties and behaviors are bundled into individual objects. It helps to get a proper level of abstraction to not get bogged down with details, but still allows you to do it if you want.\n",
    "* however #1 - no explicit encapsulation: \"After all, we're all consenting adults here.\"\n",
    "    * However, contrary to other OOP supporting languages, Python does not support encapsulation. Meaning there is no private keyword\n",
    "    * Instead, it relies on the convention: a class variable that should not directly be accessed should be prefixed with an underscore. It's more of an agreement and it can be violated, So if there is a method within tensorflow package that you dont like, in python you can overwrite it, change the state of a private field, and then prey that everytjing still works.\n",
    "* however #2 - no class interface, only (multi)inheritance\n",
    "    * python does not have any equivalent of interfaces . Since Python does support multiple inheritance, you can easily emulate the equivalence of interfaces. ... Interfaces are concepts that belong to statically typed languages such as Java or C#, and do not really apply to dynamic language such as Python\n",
    "* multi-paradigm\n",
    "    * object oriented programming\n",
    "    * structured programming\n",
    "    * functional programming\n",
    "* interpreted, meaning that you do not have to link it and compile in order to run it. It's evaluated as the script goes, line be line. It also means that some kind of errors will not be communicated until the faulty line is actaully executed.\n",
    "* strongly typed\n",
    "    *  it forbidds operations that are not well-defined rather than silently attempting to make sense of them. for example, adding a number to a string\n",
    "* dynamically typed\n",
    "    * Python doesn't know about the type of the variable until the code is run\n",
    "* duck typing\n",
    "    * \"If it walks like a duck and it quacks like a duck, then it must be a duck\"‚Äî to determine if an object can be used for a particular purpose. With normal typing, suitability is determined by an object's type. In duck typing, an object's suitability is determined by the presence of certain methods and properties, rather than the type of the object itself.\n",
    "* garbage collector\n",
    "    * Python, just like most of the modern languages, has a garbage collector which will manage memory and clean any unsed data, it does it by reference counting and cycle-detecing.\n",
    "* designed for code clarity\n",
    "    * ex loops: `for element in collection`\n",
    "* object introspection\n",
    "    * By using introspection, we can dynamically examine python objects. Code Introspection is used for examining the classes, methods, objects, modules, keywords and get information about them so that we can utilize it.\n",
    "* interactive mode (terminal / IPython)\n",
    "* interfaces to many popular programming languages:\n",
    "    * C++\n",
    "    * Java\n",
    "    * .NET\n",
    "    * and many others\n",
    "* has it's own package manager - pip\n",
    "* before writing a library - check if it exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python | Data Structures | List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Ok! Now that we are done with the formalities, let's get our hands dirty and remind ourselves of the most common and widely used data types available in Python.\n",
    "\n",
    "As a data scientist you will be relying more on arrays than lists, and we will cover arrays in few slides, it is still important to know a thing or two about python's lists, as we will be using them a lot. \n",
    "Actualy I cant recall when was the last time i wrote a python script that did not use a list.\n",
    "\n",
    "And also some of the knowledge from the lists can be applied to the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "my_list = [0]*10\n",
    "my_list = list(range(10))\n",
    "my_list\n",
    "my_list[2]\n",
    "my_list[-1]\n",
    "my_list[4:10]\n",
    "my_list[4:]\n",
    "my_list[:]\n",
    "\n",
    "#2D - we can create a 2d list\n",
    "r = 4\n",
    "c = 5\n",
    "list2d = [[0]*c for _ in range(r)]  # this is called list comprehension\n",
    "list2d[0]\n",
    "list2d[0][3]\n",
    "\n",
    "a = []\n",
    "for y in range(r):\n",
    "    a.append([])\n",
    "    for x in range(c):\n",
    "        a[-1].append((x+1)*(y+1)) # we can also pre-pend elements, but it's an expensive operation\n",
    "print(a)\n",
    "print(a[1:3])\n",
    "print(a[1:3][1:3]) # won't work :(\n",
    "# instead\n",
    "print(a[1][1:3]) \n",
    "print(a[2][1:3]) \n",
    "# what's worth mentioning is people often call 2d list \n",
    "# a 2d array - it's not the same. \n",
    "# A 2D list is more precisely a list of lists which only \n",
    "# sometimes happens to be of the rectangular shape.\n",
    "# What is the difference between 2d list and python's array, \n",
    "# you may ask\n",
    "# For 99% cases you are fine with lists - if you haven't used\n",
    "# python's arrays so far then most likely you just never needed\n",
    "# to - and that's fine!\n",
    "# arrays by definition are homogenous - all objects within \n",
    "# array must be of the same type\n",
    "# lists are heterogenous, they don't care for data type\n",
    "# arrays tend to be faster and more memory efficient, but for \n",
    "# some operations they can be super slow - like expending the array\n",
    "#     the array module is used to interface with C code\n",
    "# lists are heavier, as every single element is a python object, \n",
    "#     but on the other hand adding new elements happens in amortized\n",
    "# constant cost\n",
    "# we will not be going into more details on python's array, as we will\n",
    "# be covering something more interesting in few slides\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python | Data Structures | Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "dictionaries are a key-value stores\n",
    "\n",
    "```python\n",
    "d = {}\n",
    "d = {'a': 1, 'b': 2}\n",
    "```\n",
    "\n",
    "what can be a key?\n",
    "* dictionary key must be of a type that is immutable.\n",
    "* For example, you can use an integer, float, string, or Boolean as a dictionary key.\n",
    "* However, neither a list nor another dictionary can serve as a dictionary key, because lists and dictionaries are mutable.\n",
    "* tuples are immutable, however, and can be used.\n",
    "    * The major difference between tuples and lists is that a list is mutable, whereas a tuple is immutable. This means that a list can be changed, but a tuple cannot.\n",
    "\n",
    "\n",
    "```python\n",
    "d = {[0,0]: 1} # fail\n",
    "d = {(0,0): 1}\n",
    "```\n",
    "\n",
    "just as with lists, dictionaries can be created with a comprehension:\n",
    "```python\n",
    "d = {key: key**2 for key in range(5) if key%2==0}\n",
    "```\n",
    "\n",
    "to access dict elements you can use standard:\n",
    "```\n",
    "d[0]\n",
    "```\n",
    "you can get all the keys and values as a separate lists:\n",
    "```\n",
    "d.keys()\n",
    "d.values()\n",
    "```\n",
    "\n",
    "or iterate over key value pairs:\n",
    "```\n",
    "for k, v in d.items():\n",
    "    print(k,v)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python | Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "later in one of the excersises we will be using a global variable, and to better understand how it works in python we have to take a look into scopes.\n",
    "variable scope says where in the code we can refer to the particular variable. let's do a short example:\n",
    "\n",
    "```python\n",
    "x = 4 # comment it in in the end\n",
    "\n",
    "def fun():\n",
    "    #global x\n",
    "    #x = x+1\n",
    "    return x+1\n",
    "\n",
    "fun() #run\n",
    "x # lets see the value, no surprise here\n",
    "# fun()\n",
    "# fun()\n",
    "x\n",
    "```\n",
    "\n",
    "in tensorflow a very similar mechanism based on scopes allows for managing graphs, but more on that later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python | Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "this is a shrt one - i only have two operators that i wanted to show you very quickly, which are still quite useful in your daily life:\n",
    "\n",
    "```python\n",
    "print('Power \\t\\t3**2 =\\t', 3**2) # instead of using math library or multiplying in a loop\n",
    "print('Floor division \\t3//2 =\\t', 3//2) # instead of casting the result to int explicitly\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python | Anonymous function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "anonymous functions, also called lambda function, allow for defining a new function inline. it's a very useful tool that you will find yourself using a lot, as it gives you the flexibility without sacrificing readibility. let's see an example:\n",
    "\n",
    "```python\n",
    "def pow2(x):\n",
    "    return x ** 2\n",
    "\n",
    "pow2(2)\n",
    "\n",
    "pow2_lambda = lambda x: x ** 2\n",
    "pow2_lambda(2)\n",
    "\n",
    "l = range(10)\n",
    "list(filter(lambda x: (x%2 == 0) , l))\n",
    "\n",
    "list(map(lambda x: x ** 2 , l))\n",
    "```\n",
    "\n",
    "however, in more complex projects using lambda functions can lead to repeativness and, at the end, a mess. You will have to make a call here.\n",
    "\n",
    "still, in especially in prototyping like you do in a jupyter notebook, it's a great tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python | \\*args and \\*\\*kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "in all frameworks, being it tensorflow or pytorch, sooner or later you will meet a function that has\n",
    "\\*args and \\*\\*kwargs in the definition. So, what is the \\*args and \\*\\*kwargs?\n",
    "\n",
    "let's do it by example:\n",
    "```python\n",
    "# unpacking *args\n",
    "a = [1,2,3]\n",
    "print(*a) # print(a[0], a[1], a[2])\n",
    "print(\"{} {}\".format(*a))\n",
    "\n",
    "# it can be also used to extract a head member of the list\n",
    "raw_data = ['label', 'width', 'height', 'depth']\n",
    "\n",
    "(label, *data) = raw_data\n",
    "print(label)\n",
    "print(data)\n",
    "\n",
    "# packing *args\n",
    "from random import randint\n",
    "def roll(*dice):\n",
    "    return sum(randint(1, die) for die in dice)\n",
    "\n",
    "roll(6, 6)\n",
    "roll(6, 6, 6)\n",
    "\n",
    "# **kwargs - keyword arguments\n",
    "def data2xml(label, **attr):\n",
    "    attr_list = ['{}=\"{}\"'.format(name, value) for name, value in attr.items()]\n",
    "    print('<{} {} \\>'.format(label, ' '.join(attr_list)))\n",
    "\n",
    "data2xml('my_label', width=10, height=20, depth=30)\n",
    "```\n",
    "\n",
    "you can use both args and kwargs, but there is an order: first defined parameters, then list of args, and only then kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python | What makes your Python code better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### PEP8 Style Guide\n",
    "\n",
    "Guidelines for:\n",
    "* Code layout (Indentation - Tabs or Spaces?, Maximum Line Length, Imports etc.)\n",
    "* String quotes\n",
    "* Whitespaces\n",
    "* Naming conventions\n",
    "* Overriding principles\n",
    "\n",
    "Validate your code with pycodestyle utility (pep8 [just the utility] has been renamed to pycodestyle (GitHub issue #466)).\n",
    "\n",
    "```bash\n",
    "$ pip install pep8 # or: pip install pycodestyle\n",
    "$ pycodestyle <directory or a file>\n",
    "  python101/math.py:4:1: E302 expected 2 blank lines, found 1\n",
    "  python101/math.py:4:10: E231 missing whitespace after ','\n",
    "```\n",
    "Examples: https://pypi.org/project/pep8/, more at https://www.python.org/dev/peps/pep-0008/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### PEP257 Docstrings\n",
    "\n",
    "A docstring is a string literal that occurs as the first statement in a module, function, class, or method definition. Such a docstring becomes the doc special attribute of that object.\n",
    "\n",
    "* All modules should normally have docstrings, and all functions and classes exported by a module should also have docstrings.\n",
    "* Public methods (including the init constructor) should also have docstrings.\n",
    "* A package may be documented in the module docstring of the init.py file in the package directory.\n",
    "* For consistency, always use \"\"\"triple double quotes\"\"\"\n",
    "* Validate your code with pep257 utility.\n",
    "\n",
    "```bash\n",
    "pip install pep257\n",
    "```\n",
    "\n",
    "* Good read: https://blog.dolphm.com/pep257-good-python-docstrings-by-example/\n",
    "\n",
    "```bash\n",
    "$ pep257 python101/\n",
    "  python101/__init__.py:1 at module level:\n",
    "          D104: Missing docstring in public package\n",
    "  python101/math.py:1 at module level:\n",
    "          D100: Missing docstring in public module\n",
    "  python101/math.py:1 in public function `add`:\n",
    "          D103: Missing docstring in public function\n",
    "  python101/math.py:4 in public function `sub`:\n",
    "          D103: Missing docstring in public function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Typical Project Structure\n",
    "\n",
    "```\n",
    "/example_pkg\n",
    "--/example_pkg\n",
    "----__init__.py\n",
    "----my_script.py\n",
    "--setup.py\n",
    "--LICENSE\n",
    "--README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Packaging\n",
    "\n",
    "1. Prepare the directory tree as shown in Typical project structure\n",
    "1. Install required packages:\n",
    "    ```bash\n",
    "    $ pip install setuptools wheel\n",
    "    ```\n",
    "    \n",
    "1. Run this command from the same directory where setup.py is located:\n",
    "\n",
    "    ```bash\n",
    "    $ python setup.py sdist bdist_wheel\n",
    "    ```\n",
    "1. This will created a dist directory with built package. To test:\n",
    "    1. Install created package:\n",
    "    \n",
    "        ```bash\n",
    "        $ python -m pip install dist/example_pkg-0.0.1-py3-none-any.whl\n",
    "        ```\n",
    "        \n",
    "    2. Go to a different directory, enter Python shell, and try entering the code below:\n",
    "    \n",
    "    ```python\n",
    "    import example_pkg\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NumPy\n",
    "\n",
    "* linear algegra library for python\n",
    "* main building block for data-oriented libaries\n",
    "* It's fast\n",
    "* Even faster if you install it using Anaconda\n",
    "\n",
    "```bash\n",
    "pip install numpy\n",
    "# or\n",
    "conda install -y numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now that we have refeshed our python, it's time to learn about our first python data analysis library in this lecture - the NumPy.\n",
    "\n",
    "* it's a linear algebra library for python\n",
    "* it's super important for Data science - almost all python data-oriented libraryies rely on NumPy as their main building block. multidimensional matrices, or tensors, take a lot of inspiration from numpy's arrays. Tensors are similar to NumPy‚Äôs ndarrays, with the addition being that Tensors can also be used on a GPU. If you know numpy arrays it is easy to jump into the world of tensors as the two share a lot of common features and both can interface with each other.\n",
    "* python being an interpreted language one might think that processing huge arrays of data will take ages, but, again, there are C libraries bindings thanks to which NumPy can be blazingly fast.\n",
    "\n",
    "* How do I get numpu? super easy, with either python's package manager or with anaconda. if you want to use the most of your CPU's vector extensions you should really use the latter one. Once it's installed - you can do it within notebook using jupyter's magic command `!pip install numpy`. Here in notebook I typed pip instead of conda - last few times i tried using conda through the cells magic command there seem to be an issue with conda (it might be due to conda being interactive during installation, but even with -y flag it fails for me so i will have to investigate this issue later), but if you have access to the CLI you can install numpy with conda there, or you can just stick with pip installation for now.\n",
    "\n",
    "* Once it's installed you just have to import it to use it:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NumPy | Array vs Python List\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/array_vs_list.png\" />\n",
    "    <i>Source: <a href=\"https://jakevdp.github.io/PythonDataScienceHandbook/02.01-understanding-data-types.html\" target=\"_blank\">jakevdp.github.io/PythonDataScienceHandbook/02.01-understanding-data-types.html</a></i>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "what is a python list and how it differes from an array?\n",
    "\n",
    "At the implementation level, the array essentially contains a single pointer to one contiguous block of data. This does have consequences in both usage and performance.\n",
    "Because of the single pointer, pointing at the head of the array, we have to make the assumption that all objects in the array are of the same size, so, at the low level, we can easily calcuate the memory address of the cell. for instance integer takes 4 bytes, so to access the 3rd element we have to move by 8 bytes from the pointer and read following 4 bytes. with various data types it would have been impossible.\n",
    "another consequence is that array gives us quick access, both read and write, to any given cell, but it's also super time consuming to extend existing array with additonal rows or columns, as basically we have to create a new larger array containing a copy of the previous one.\n",
    "\n",
    "The Python list, on the other hand, contains a pointer to a block of pointers, each of which in turn points to a full Python object like the Python integer we saw earlier.\n",
    "\n",
    "NumPy arrays give you a huge performance advantage over python's arrays and lists in some operations not only because it's an array, but also due to the approach that numpy takes to all operations on arrays. Instead of treating the array as a collection of elements and executing a given operation on each of the elments, numpy takes advantage of the vectorization and applies the operation to multiple elements of the array at once. \n",
    "\n",
    "Modern CPUs, have dedicated hardware registers called Vector-Registers (for example the SSE and AVX registries), that are capable of operating on multiple operands (of the same type/size) simultaneously, introducing a parallelism referred to as ‚ÄòSingle Instruction Multiple Data‚Äô (or SIMD) mechanism. Without vector registers the data would have been processed just like in a standard python list or array - one element at a time, or a Single Instruction Single Data, if you will."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NumPy | Creating Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "let's start with how to create a numpy array. as a datascientist this is one of the things that you will find yourself doing over and over again, so it's good to memorize some of the available options here, as there are many different ways to create and initialize a numpy array:\n",
    "```python\n",
    "# single dimensional list/array\n",
    "my_list = [0,1,2,3,4]\n",
    "np.array(my_list)\n",
    "# two dimensional\n",
    "my_mat = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "np.array(my_mat)\n",
    "\n",
    "# usually however, you will be using numpys built in methods to create np arrays a lot faster\n",
    "\n",
    "np.arange(0,10) # similar to python's range, produce an array from a sequence of numbers starint from 0 and ending on 10 exclusive.\n",
    "np.arange(0,10, 2) # create a sequence starting with 0 with every other number, as the step is 2\n",
    "\n",
    "np.arange(0,10).reshape(2,5) # reshape\n",
    "\n",
    "np.zeros(3)\n",
    "np.zeros((5,5)) # rows, columns\n",
    "\n",
    "np.ones((2,4))\n",
    "\n",
    "np.linspace(0,10,6) # dont confuse it with arrange, arrange will give points in increments of integer, and linspace\n",
    "# will give us exactly N points in given range\n",
    "np.linspace(0,10,101)\n",
    "# linspace is very useful when you want to plot a function\n",
    "\n",
    "np.eye(4) # NxN as identity matrix must be square,\n",
    "# identity matrix is useful matrix is a useful matrix when dealing with linear algegra problems\n",
    "\n",
    "np.random.rand(2) # will populate given range with a population of uniform distribution over 0 to 1\n",
    "np.random.rand(2,2) # weirdly enough, for more dimensions we do not pass tuple, but instead we just add another argument\n",
    "\n",
    "np.random.randint(0,10)  # will draw a single int from given range\n",
    "np.random.randint(0,10,(3,3)) # will draw a 3x3 array from given range\n",
    "\n",
    "np.random.randn(4) # draw N samples for normal distribution centered around 0\n",
    "np.random.randn(4,4)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NumPy | Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# For example, the coordinates of a point in 3D space [1, 2, 3] has one axis. That axis has 3 elements in it, so we say it has a length of 3.\n",
    "np.array([  0, 1, 2])\n",
    "\n",
    "#In the next example, the array has 2 axes. The first axis has a length of 2, the second axis has a length of 3.\n",
    "\n",
    "a = np.array([[  0, 1, 2],\n",
    "              [ 10,  11,  12]])\n",
    "\n",
    "# ndarray.ndim\n",
    "# the number of axes (dimensions) of the array.\n",
    "a.ndim\n",
    "\n",
    "# ndarray.shape\n",
    "# the dimensions of the array. This is a tuple of integers indicating the size of the array in each dimension.\n",
    "# For a matrix with n rows and m columns, shape will be (n,m). \n",
    "# The length of the shape tuple is therefore the number of axes, ndim.\n",
    "a.shape\n",
    "\n",
    "# ndarray.size\n",
    "# the total number of elements of the array. This is equal to the product of the elements of shape.\n",
    "print(f'ndarray.size = {a.size}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NumPy | Data types\n",
    "\n",
    "* NumPy arrays are homogeneous (elements of the same type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "l = np.array([1,2])\n",
    "print(l, l.dtype)\n",
    "\n",
    "l = np.array([1.0,2.0])\n",
    "print(l, l.dtype)\n",
    "\n",
    "l = np.array([1.0,2.0], dtype=np.int16)\n",
    "print(l, l.dtype)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NumPy | Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "mat = np.arange(9).reshape(3, 3)\n",
    "mat\n",
    "\n",
    "mat[0][1] # while we can use syntax just like in python's list\n",
    "mat[0,1]  # a coma-seperated indices became a golden standard for getting a value out of numpy;s array\n",
    "mat[:,1]\n",
    "mat[1,:]\n",
    "mat[:2,1:]\n",
    "mat[:] # to access all elements\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NumPy | Boolean Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Boolean masking is one of my favorite party tricks that i like to use to impress people at the bar.\n",
    "\n",
    "When we index arrays with integers we are explicitly providing the indices to pick. With boolean indices the approach is different; we explicitly choose which items in the array we want and which ones we don‚Äôt.\n",
    "\n",
    "The most natural way one can think of for boolean indexing is to use boolean arrays that have the same shape as the original array:\n",
    "\n",
    "```python\n",
    "mat = np.arange(12).reshape(3, 4)\n",
    "mat\n",
    "mat.shape\n",
    "b = mat>4\n",
    "b\n",
    "b.shape\n",
    "# now that we have the mask, numpy allows us to use it as an index:\n",
    "mat[b]\n",
    "# notice that the shape is different.\n",
    "mat[b].shape\n",
    "# When you apply the mask the information abouyt the shape does not\n",
    "# get carried over to the filtered array, as in most cases you would end up with jagged arrays and numpy\n",
    "# does not support that kind of thing.\n",
    "\n",
    "# different forms of expressions can be used to create a mask,\n",
    "# for instance if we want to select all elements which multiplied by 2 are equal to the element to the 2nd power,\n",
    "# we can use:\n",
    "mat[ (mat*2) == (mat**2) ]\n",
    "\n",
    "# now, we can also inverse the mask by either changing the condition we defined above,\n",
    "# or we can simply use logical not:\n",
    "mat[np.logical_not(b)]\n",
    "# now that we have access to all elements smaller than 4, let's reset them to zero\n",
    "mat[np.logical_not(b)] = 0\n",
    "mat\n",
    "# but how did it happen, that we managed to assign a single value to multiple elements? Let's check it out on the next slide!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NumPy | Broadcasting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Arithmetic operations on arrays are usually done on corresponding elements. If two arrays are of exactly the same shape, then these operations are smoothly performed.\n",
    "\n",
    "The term broadcasting describes how numpy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is ‚Äúbroadcast‚Äù across the larger array so that they have compatible shapes\n",
    "\n",
    "```python\n",
    "a = np.arange(11)\n",
    "a\n",
    "b = a[:5]\n",
    "b\n",
    "b[:] = 999 # mind the colon - it means we grab all elements. Without using it we will simply convert variable b\n",
    "# from being a numpy array to being just an integer 999. This is the example of broadcasting. We take array and we\n",
    "# apply an operation to it - in this case assignment - using an object of a different shape. In this case the\n",
    "# 999 will be broadcasted into the array of the same shape as the object 'a', and will be then applied in 1-1 \n",
    "# matching between the indices of two array.\n",
    "b\n",
    "\n",
    "# i will point one issue here, with what we have just done. You see, to avioid being a memory hog when \n",
    "# dealing with larger matrices, numpy handles matrices as references, and when we grabbed subarray of 'a',\n",
    "# we did not create a new array, we just got few references to the first 5 objects. and as such if we display 'a':\n",
    "a\n",
    "# to avoid this issue we can use .copy() to create a new instance with same values\n",
    "b_copy = list_f[:5].copy()\n",
    "b_copy[:] = 33\n",
    "b_copy\n",
    "a\n",
    "\n",
    "# we can use broadcast to do all kinds of things: multiply, add, subtract, divide.\n",
    "# we can do it on all elements, a filtered subset or on rows or columns\n",
    "a = np.ones((3,3))\n",
    "a\n",
    "a * [1,2,3] \n",
    "a * [[1],[2],[3]]\n",
    "a * [1,2,3] * [[1], [2], [3]]\n",
    "# but we have to remember that that we can only use objects that can be scaled up to the other's size,\n",
    "# so things like same number of columns or rows are important\n",
    "# a * [2,2] # this will cause an error\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NumPy | Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "np.random.seed(101)\n",
    "a = np.random.randint(1,3,(2,2))\n",
    "print(a)\n",
    "a.min()\n",
    "a.max()\n",
    "a.argmin()\n",
    "a.argmax()\n",
    "\n",
    "b = np.random.randint(1,3,(2,2))\n",
    "print(b)\n",
    "\n",
    "a*5\n",
    "a*b # it's an element wise multiplication\n",
    "a.dot(b)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Visualization | Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* one of the most common popular plotting library\n",
    "* it includes a pyplot, which is a collection of functions that make matplotlib work like MATLAB, and this is what we use in python to interface with matplotlib\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "plt.plot([1, 2, 3, 4])\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()\n",
    "\n",
    "# You may be wondering why the x-axis ranges from 0-3 and the y-axis from 1-4.\n",
    "# If you provide a single list or array to plot, matplotlib assumes it is a sequence of y values,\n",
    "# and automatically generates the x values for you. Since python ranges start with 0, \n",
    "# the default x vector has the same length as y but starts with 0. Hence the x data are [0, 1, 2, 3].\n",
    "\n",
    "# we can also pass the x values explicitly:\n",
    "plt.clf() # matplot lib carries the states between plots, so if you do not want to have multiple plots\n",
    "# on a single figure, you can clear the figure first\n",
    "plt.plot([1,2,3,4],[1, 2, 3, 40])\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()\n",
    "\n",
    "# we can also use numpy arrays as the input to pyplot\n",
    "plt.clf()\n",
    "x = np.linspace(0, np.pi*2, 100)\n",
    "y = np.sin(x)\n",
    "# plt.plot(x, y) # plot will draw continues line between points, as you may have noticed\n",
    "plt.plot(x, y, 'ro') # we can use 3rd parameter to have points marked as red  filled circles\n",
    "plt.plot(x, y, 'r-') # the default line can be achieved by using a dash\n",
    "\n",
    "# and you even can have multiple plots in a single call, you just have to keep them in order:\n",
    "plt.clf()\n",
    "plt.plot(x, y, 'r-', x, y*(-1), 'b^')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "# another type of a plot we might want to draw is a scatter plot. \n",
    "# A scatter plot is a type of plot that display values for typically two variables for a set of data.\n",
    "# additionally If the points have a category, or are coded in general, one additional variable can be displayed\n",
    "# as a color\n",
    "N = 500\n",
    "x = np.linspace(0, 1, N)\n",
    "y = np.random.rand(N)\n",
    "categories = [i%5 for i in range(N)]\n",
    "area = np.pi*3\n",
    "\n",
    "# you can also draw multiple figures on a single canvas\n",
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle('Vertically stacked subplots')\n",
    "axs[0].scatter(x, y, s=np.abs(np.random.rand(N))*100, c=categories)\n",
    "axs[1].plot(x, x)\n",
    "axs[1].grid()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Visualization | Real example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "from sklearn import datasets \n",
    "# pip install scikit-learn\n",
    "# or\n",
    "# conda install scikit-learn\n",
    "iris = datasets.load_iris()\n",
    "iris\n",
    "iris.data.shape\n",
    "iris.target.shape\n",
    "\n",
    "# If you go to the IRIS dataset website in the description we\n",
    "# can see what is the meaning of the column that we see\n",
    "# it is Sepal Length, Sepal Width, Petal Length, Petal Width, Iris type\n",
    "columns = [\"[0] Sepal Length\", \"[1] Sepal Width\", \"[2] Petal Length\", \"[3] Petal Width\"]\n",
    "\n",
    "i = 0\n",
    "j = 1\n",
    "plt.scatter(iris.data[:, i], iris.data[:, j], c=iris.target)\n",
    "plt.xlabel(columns[i])\n",
    "plt.ylabel(columns[j])\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Visualization | Real Example 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "from mpl_toolkits.mplot3d import Axes3D # <--- important for 3d plotting\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "i = 0\n",
    "j = 1\n",
    "k = 3\n",
    "ax.scatter(iris.data[:,i], iris.data[:,j], iris.data[:,k], c=iris.target)\n",
    "\n",
    "ax.set_xlabel(columns[i])\n",
    "ax.set_ylabel(columns[j])\n",
    "ax.set_zlabel(columns[k])\n",
    "\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Visualization | Real Example w/ dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "iris.data.shape\n",
    "x_pca3 = PCA(n_components=3).fit_transform(iris.data) # PCA is one of the few possible methods to reduce the number\n",
    "# of dimensions. In your data it will find the feature that contributes the least and will remove it completely,\n",
    "# while adjusting other features to accomodate for the loss of information. THe eaiest example is to take a tree - \n",
    "# it's a 3 dimensional object which has width, height and depth. The tree casts a shadow, shadow is two dimensional,\n",
    "# it does not have depth feature, but both width and height have been adjusted.\n",
    "# Fun thing is that if you keep the information on how the reduction was performed with PCA, you can get a lossy \n",
    "# compression method. \n",
    "x_pca3.shape\n",
    "x_pca3\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x_pca3[:,0], x_pca3[:,1], x_pca3[:,2], c=iris.target)\n",
    "plt.show()\n",
    "\n",
    "# x_pca2 = PCA(n_components=2).fit_transform(iris.data)\n",
    "\n",
    "# plt.scatter(x_pca2[:, 0], x_pca2[:, 1], c=iris.target)\n",
    "# plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üêº Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pandas\n",
    "\n",
    "* open-source library built on top of NumPy\n",
    "* fast analysis, data cleaning and preparation\n",
    "* built-in visualization features\n",
    "* Excel for Python\n",
    "\n",
    "```bash\n",
    "pip install pandas\n",
    "# or\n",
    "conda install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(data_url)# we can use it to download CSV file from internet\n",
    "# but we will continue on using the IRIS dataset that we already have loaded\n",
    "\n",
    "df = pd.DataFrame(data=iris.data, columns=columns)\n",
    "df\n",
    "df['[0] Sepal Length']\n",
    "df[['[0] Sepal Length', '[1] Sepal Width']] # mind it's a list of columns!\n",
    "df['[0] Sepal Length'].max()\n",
    "df['[0] Sepal Length'].min()\n",
    "df['[0] Sepal Length'].mean()\n",
    "df.describe()\n",
    "df['[0] Sepal Length'] > 5.84\n",
    "df[df['[0] Sepal Length'] > 5.84]\n",
    "# Pandas is great for preliminary data exploration,\n",
    "# when you want to find if there is any relation between features,\n",
    "# if there are any features missing, in this case it also have a method\n",
    "#    that will help you with the gaps.\n",
    "#.      df.fillna(0)\n",
    "# our dataset is without gaps, but if you have any in yours\n",
    "# you can use this method to either fill the gaps with 0s or\n",
    "# with the mean value for a given feature\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Graph Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph Computing | Concept\n",
    "\n",
    "* TensorFlow - define graph statically in a session before model can be run\n",
    "* PyTorch - define, change and execute graph nodes as you go\n",
    "\n",
    "**Both TensorFlow and PyTorch process any model as directed acyclic graph (DAG)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"files/graphs.png\" alt=\"DAG vs DCG\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph Computing | Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ res = (15*5) / (15+5) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ a = 5 $$\n",
    "$$ b = 15 $$\n",
    "$$ prod = a * b $$\n",
    "$$ sum = a + b $$\n",
    "$$ res = prod / sum $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://miro.medium.com/max/700/1*oo8djcq1ykZxxsSEo6jx2g.gif\" alt=\"Graph processing order\" />\n",
    "    <div><i>Source: <a href=\"https://medium.com/@d3lm/understand-tensorflow-by-mimicking-its-api-from-scratch-faa55787170d\" target=\"_blank\">medium.com</a></i></div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We are going to manually create a small network, and by manual i mean that we will not be using neither tensorflow nor pytorch. we will create few classes that will try to mimic what these framework do.\n",
    "\n",
    "this will really help build a nice fundation for your understanding, we are not going to do any complex here, it's gonna be very primitive, but i believe it's really helpful to understand the concept of how ot works underneath. We will implement a simple network, just like the one that we have just seen on the previous slide, so we will need a base class for our operations, actual operations, nodes to hold information about variables state, same goes for graph and session, and also a placeholder that acts as a input to the network.\n",
    "\n",
    "so ,this will also be a nice refresher of an object oriented programming,\n",
    "\n",
    "let's get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph Framework | Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "First, we have to implement base class for all operations\n",
    "\n",
    "To complete this class we will need to have fields for input nodes, output nodes, and a method to perform actual operation, which will be overwritten by actual implementation of the operations.\n",
    "\n",
    "```python\n",
    "class Operation(object):\n",
    "    def __init__(self, input_nodes=[]):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.output_nodes = []\n",
    "        \n",
    "        for node in input_nodes:\n",
    "            # we want to add a reference to this operation to the input nodes\n",
    "            # to let them know that this is the node to which they will feed their output\n",
    "            node.output_nodes.append(self)\n",
    "        \n",
    "        _default_graph.operations.append(self)\n",
    "    \n",
    "    def compute(self):\n",
    "        raise NotImplemented()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph Framework | Operations | Add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "class Add(Operation):\n",
    "    def __init__(self, x, y):\n",
    "        # because we are adding these two things togeter, they are basically our input nodes for our operation\n",
    "        # let,s go ahead and call the constructor of the operation class.\n",
    "        super().__init__([x, y])\n",
    "    \n",
    "    def compute(self, x_var, y_var):\n",
    "        self.inputs = [x_var, y_var]\n",
    "        return x_var + y_var\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph Framework | Operations | Multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "class Mul(Operation):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__([x, y])\n",
    "    \n",
    "    def compute(self, x_var, y_var):\n",
    "        self.inputs = [x_var, y_var]\n",
    "        return x_var * y_var\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph Framework | Operations | MatMul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "class MatMul(Operation):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__([x, y])\n",
    "    \n",
    "    def compute(self, x_var, y_var):\n",
    "        self.inputs = [x_var, y_var]\n",
    "        return x_var.dot(y_var)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph Framework | Placeholder\n",
    "\n",
    "Placeholder - a special node which is used as data input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "class Placeholder(object):\n",
    "    def __init__(self):\n",
    "        self.output_nodes = []\n",
    "        _default_graph.placeholders.append(self)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph Framework | Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "class Variable(object):\n",
    "    def __init__(self, initial_value=None):\n",
    "        # the initial value can be specified or not, if it's not then it \n",
    "        # might be a good idea to initialize it randomly\n",
    "        # but w are leaving this part to the uyser\n",
    "        self.value = initial_value\n",
    "        self.output_nodes = []\n",
    "        \n",
    "        _default_graph.variables.append(self)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph Framework | Graph Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "we discussed this default graph, its an glogal objexct, lets create an object for it\n",
    "\n",
    "```python\n",
    "class Graph(object):\n",
    "    def __init__(self):\n",
    "        self.operations = []\n",
    "        self.placeholders = []\n",
    "        self.variables = []\n",
    "    \n",
    "    def set_as_default(self):\n",
    "        global _default_graph\n",
    "        _default_graph = self\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph Framework | Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "now that the graph has all the nodes, lets create a runtime for this graph - a session.\n",
    "```python\n",
    "class Session(object):\n",
    "    def run(self, operation, feed_dict={}):\n",
    "        nodes_postorder = self._traverse_postorder(operation)\n",
    "        \n",
    "        for node in nodes_postorder:\n",
    "            if type(node) == Placeholder:\n",
    "                node.output = feed_dict[node]\n",
    "            elif type(node) == Variable:\n",
    "                node.output = node.value\n",
    "            else:\n",
    "                node.inputs = [input_node.output for input_node in node.input_nodes]\n",
    "                node.output = node.compute(*node.inputs)\n",
    "            \n",
    "            if type(node.output) == list:\n",
    "                node.output = np.array(node.output)\n",
    "        return operation.output\n",
    "                \n",
    "    def _traverse_postorder(self, operation):\n",
    "        nodes_postorder = []\n",
    "        \n",
    "        def recurse(node):\n",
    "            if isinstance(node, Operation):\n",
    "                for input_node in node.input_nodes:\n",
    "                    recurse(input_node)\n",
    "            nodes_postorder.append(node)\n",
    "            \n",
    "        recurse(operation)\n",
    "        return nodes_postorder\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph Framework | Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "g = Graph()\n",
    "g.set_as_default()\n",
    "\n",
    "A = Variable(10)\n",
    "b = Variable(1)\n",
    "x = Placeholder()\n",
    "\n",
    "y = Mul(A, x)\n",
    "z = Add(y, b)\n",
    "\n",
    "sess = Session()\n",
    "result = sess.run(operation=z, feed_dict={x:10})\n",
    "result\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## TensorFlow | TensorFlow and Keras\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://www.pyimagesearch.com/wp-content/uploads/2019/10/keras_vs_tfdotkeras_relationship.png\" alt=\"The intertwined relationship between Keras and TensorFlow\" />\n",
    "    <div><i>Source: <a href=\"https://www.pyimagesearch.com/2019/10/21/keras-vs-tf-keras-whats-the-difference-in-tensorflow-2-0/\" target=\"_blank\">pyimagesearch.com</a></i></div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The current version of the TensorFlow is 2.3 and it's a rather different than TensorFlow 1, if that's what you are used too. \n",
    "\n",
    "So back in a day, in the times of tensorflow 1, keras used to be an separate thing from tensorflow. tensorflow was a computational framework with all the quirks and features, giving you a lot of flexibility, and because of that was quite complex to use. It gave a lot of freedom, but it came at a cost of flat learning curve.\n",
    "\n",
    "Keras was created to solve some of these issues, not only in tensorflow, but in geenral, as keras started as a high level deep learning api that was nothing more than an interface to different backends, like tensorflow, theano or apache mxnet. Theano was the default one. Keras was not without fault, however, as it allowed for high level definitions, but lacked flexibility that comes with low lever APIs, like the ones in tensorflow\n",
    "\n",
    "but then, with tf 1.10, keras api layer became available in tensorflow. not fully, it was always a catch up game with these two, but it was there, gicving an ability for easier development with tensorflow. tensorflow also became a default backend for keras, and so it went.\n",
    "\n",
    "Now that TensorFlow 2.0 is released both keras and tf.keras are in sync, implying that keras and tf.keras are still separate projects; however, developers should start using tf.keras moving forward as the keras package will only support bug fixes.\n",
    "\n",
    "one of the major differences in tensorflow is that you no longer have to run things in session. ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## TensorFlow | Session Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "aka tensorflow 2 in tensorflow 1 mode\n",
    "```python\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "print(tf.executing_eagerly())\n",
    "\n",
    "a = tf.constant(5.0)\n",
    "x = tf.placeholder(dtype=tf.float32)\n",
    "b = tf.constant(6.0)\n",
    "r = a*x+b\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    result = sess.run(r, feed_dict={x: [10,10]})\n",
    "result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## TensorFlow | Eager Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__REQUIRES KERNEL RESTART ( 0 0 )__\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "print('Eager execution: ', 'enabled' if tf.executing_eagerly() else 'disabled')\n",
    "\n",
    "a = tf.constant(5.0)\n",
    "x = [10,10]\n",
    "b = tf.constant(6.0)\n",
    "r = a*x+b\n",
    "r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BACKLOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "print(tf.executing_eagerly())\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions\n",
    "\n",
    "tf.nn.softmax(predictions).numpy()\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_fn(y_train[:1], predictions).numpy()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "probability_model(x_test[:5])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
